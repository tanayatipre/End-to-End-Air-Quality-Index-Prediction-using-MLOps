name: CI/CD Pipeline

on:
  push:
    branches:
      - main
    paths-ignore:
      - 'README.md'
      - 'docs/**' 
  workflow_dispatch:
    inputs:
      full_train:
        description: 'Run full ML pipeline training and deploy new model'
        required: true 
        type: boolean
        default: true 

permissions:
  id-token: write 
  contents: read  

env: 
  MLFLOW_TRACKING_URI: https://dagshub.com/${{ github.repository }}.mlflow 
  MLFLOW_TRACKING_USERNAME: ${{ secrets.DAGSHUB_USERNAME }} 
  MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }} 

jobs:
  continuous-integration:
    name: Lint, Test, and Cache Dependencies
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9' 

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-python-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-python-
            
      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Lint code
        run: echo "TODO: Implement linting tools like pylint or flake8 here." 

      - name: Run unit tests
        run: echo "TODO: Implement your Python unit tests (e.g., using pytest) here." 


  full-model-training:
    name: Full ML Pipeline Training
    runs-on: ubuntu-latest
    needs: continuous-integration 
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.full_train == true

    outputs: 
      # Correct syntax for job outputs. The value is a string directly from a step's output.
      run_id: ${{ steps.run_pipeline.outputs.run_id }} 

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-python-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-python-
            
      - name: Install dependencies (including mlflow[s3] and dagshub for tracking)
        run: pip install -r requirements.txt mlflow[s3] dagshub

      - name: Run Full ML Pipeline Training
        id: run_pipeline 
        run: |
          echo "Running main.py to train the model..."
          python main.py
          
          LATEST_RUN_ID=$(mlflow runs list --max-results 1 --output-as json | jq -r '.[0].run_id')
          echo "Captured latest MLflow Run ID: $LATEST_RUN_ID"
          # Set the step output directly for GITHUB_OUTPUT
          # The format is 'name=value'
          echo "run_id=$LATEST_RUN_ID" >> $GITHUB_OUTPUT # Corrected: use $GITHUB_OUTPUT directly

  build-and-push-ecr-image:
    name: Build & Push Docker Image
    needs: full-model-training 
    runs-on: ubuntu-latest
    env: 
      MLFLOW_RUN_ID: ${{ needs.full-model-training.outputs.run_id }}
      GITHUB_REPOSITORY: ${{ github.repository }} 

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Install Utilities
        run: |
          sudo apt-get update
          sudo apt-get install -y jq unzip 

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build, tag, and push image to Amazon ECR
        id: build-image
        env: 
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY_NAME }}
          IMAGE_TAG: latest
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
            --build-arg MLFLOW_RUN_ID=$MLFLOW_RUN_ID \
            --build-arg MLFLOW_TRACKING_URI=${{ env.MLFLOW_TRACKING_URI }} \
            --build-arg MLFLOW_TRACKING_USERNAME=${{ env.MLFLOW_TRACKING_USERNAME }} \
            --build-arg MLFLOW_TRACKING_PASSWORD=${{ env.MLFLOW_TRACKING_PASSWORD }} \
            .
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          # The line below is for older GHA versions. Newer versions use the $GITHUB_OUTPUT approach above.
          # If still getting "set-output" deprecation warnings, this is fine for now.
          # echo "::set-output name=image::$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" 

  continuous-deployment:
    name: Deploy to Self-Hosted Runner
    needs: build-and-push-ecr-image 
    runs-on: self-hosted 
    steps:
      - name: Configure AWS credentials (if needed for pulling from ECR on self-hosted)
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
          
      - name: Login to Amazon ECR
        id: login-ecr-self-hosted
        uses: aws-actions/amazon-ecr-login@v1
      
      - name: Pull latest image
        run: |
          docker pull ${{secrets.AWS_ECR_LOGIN_URI}}/${{ secrets.ECR_REPOSITORY_NAME }}:latest

      - name: Stop and remove previous container (if running)
        run: |
          docker ps -a --filter "name=mlproj" --format "{{.ID}}" | xargs -r docker stop || true
          docker ps -a --filter "name=mlproj" --format "{{.ID}}" | xargs -r docker rm -fv || true

      - name: Run New Docker Image to serve users
        run: |
          docker run -d -p 8080:8080 --name=mlproj \
            -e 'MLFLOW_TRACKING_URI=${{ env.MLFLOW_TRACKING_URI }}' \
            -e 'MLFLOW_TRACKING_USERNAME=${{ env.MLFLOW_TRACKING_USERNAME }}' \
            -e 'MLFLOW_TRACKING_PASSWORD=${{ env.MLFLOW_TRACKING_PASSWORD }}' \
            -e 'MLFLOW_RUN_ID=${{ needs.full-model-training.outputs.run_id }}' \
            -e 'ML_ARTIFACTS_DIR=/app/artifacts/downloaded_model' \ 
            ${{secrets.AWS_ECR_LOGIN_URI}}/${{ secrets.ECR_REPOSITORY_NAME }}:latest

      - name: Clean previous images and containers (optional, careful with this)
        run: |
          docker system prune -f || true
